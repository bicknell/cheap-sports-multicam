#!/usr/bin/env python3

import argparse
import glob
import os
import sys

def collect_mp4_files(base_directory: str) -> list[list[str]]:
    """
    Collects MP4 files from subdirectories named 'cameraX' within a base directory,
    and returns them as a sorted list of lists of MP4 file paths.

    Args:
        base_directory (str): The root directory to search within.

    Returns:
        list[list[str]]: A list where each inner list contains full paths to MP4 files
                         found in a 'cameraX' subdirectory, sorted alphabetically.
                         The outer list is ordered by camera number (e.g., camera1's files first,
                         then camera2's files, and so on).
    """
    # List to store tuples of (camera_number, camera_name, full_path_to_dir) for sorting
    camera_dirs_info: list[tuple[int, str, str]] = []

    # Check if the base directory exists
    if not os.path.isdir(base_directory):
        print(f"Error: Directory '{base_directory}' not found.")
        return []

    # Iterate through items in the base directory to find camera subdirectories
    for item_name in os.listdir(base_directory):
        item_path: str = os.path.join(base_directory, item_name)

        # Check if it's a directory and matches the 'cameraX' pattern
        if os.path.isdir(item_path) and item_name.startswith("camera"):
            camera_num_str: str = item_name[6:] # Extract the number part (e.g., "1", "2")
            if camera_num_str.isdigit():
                camera_num: int = int(camera_num_str)
                camera_dirs_info.append((camera_num, item_name, item_path))

    # Sort the camera directories by their numerical suffix
    camera_dirs_info.sort(key=lambda x: x[0])

    if len(camera_dirs_info) != 4:
        print("Could not find 4 camera directories.")
        sys.exit(1)

    # List to store the final result: an array of arrays (list[list[str]])
    all_camera_mp4s: list[list[str]] = []

    # Process each sorted camera directory
    for camera_num, camera_name, camera_path in camera_dirs_info:
        # Find all .mp4 files within this camera directory
        mp4_files: list[str] = glob.glob(os.path.join(camera_path, "*.[Mm][Pp]4"))
        # Sort the files alphabetically for consistent order
        sorted_mp4_files: list[str] = sorted(mp4_files)
        if len(sorted_mp4_files) == 0:
            print(f"No video files found in {camera_path}.")
            sys.exit(1)
        all_camera_mp4s.append(sorted_mp4_files)

    return all_camera_mp4s


def construct_ffmpeg_args(files: list[list[str]], offsets: tuple[int, int, int, int], one_audio: bool, output: str, encode: str = "YouTube") -> str:

    cmd: str = "ffmpeg \\\n"

    """
    ffmpeg wants the input files as a series of -i <filename> arguments.
    """
    for n, cam_list in enumerate(files):
        # Add -i for each file in the current list
        for f in cam_list:
            cmd += f'-i {f} '
    
        cmd += '\\\n'

    """
    Construct a filter_complex filter that will combine the video.
    """
    cmd += '-filter_complex " \\\n'

    """
    Construct a concat for each camera that combines the multiple
    files generated by the camera into one video and one audio 
    stream.

    TODO: If there is only one file a concat won't work and is unnecessary.
          Need to add handling for that case.
    """
    video = 0
    for cam, cam_list in enumerate(files):
        # If there are multiple videos we must concatinate them together.
        if len(cam_list) > 1:
            # To avoid incrementing videos twice, increment a throwaway the first time.
            index = video
            cmd += '     '
            for f in cam_list:
                cmd += f'[{index},v]'
                index += 1
            cmd += f'concat=n={len(cam_list)}:v=1:a=0[v{cam}_concat]; \\\n'

            cmd += '     '
            for f in cam_list:
                cmd += f'[{video},a]'
                video += 1
            cmd += f'concat=n={len(cam_list)}:v=0:a=1[a{cam}_concat]; \\\n'

    """
    PTS-STARTPTS calculates the new timestamp for each frame by subtracting the initial
    timestamp from its current timestamp. This effectively resets the video's timeline
    to start at t=0, which is crucial for ensuring that streams align correctly, especially
    after concatenating multiple clips.

    This is also used to adjust the delay between the two cameras, note that although
    the previous code made all the delays positive, this code needs them as negative!
    """
    for cam, cam_file_list in enumerate(files):
        if len(cam_file_list) > 1:
            cmd += f'     [v{cam}_concat]scale=1920x1080,setpts=PTS-STARTPTS-{offsets[cam]:.3f}/TB[scaled{cam}]; \\\n'
        else:
            cmd += f'     [{cam},v]scale=1920x1080,setpts=PTS-STARTPTS-{offsets[cam]:.3f}/TB[scaled{cam}]; \\\n'

    """
    Process the audio portion, here there are two choices.
    """
    if one_audio:
        """
        Output a single stereo stream.

        First output a volume adjustment line for each camera so the user can
        tweak the volume.

        Second combine the 4 adjusted audio streams into a single stereo stream.

        TODO: The user should be able to specify the volume adjustments at the 
              CLI or in a config file.
        """
        for cam, cam_list in enumerate(files):
            if len(cam_file_list) > 1:
                cmd += f'     [a{cam}_concat]volume=1.0,asetpts=PTS-STARTPTS-{offsets[cam]:.3f}/TB[a{cam}_adj]; \\\n';
            else:
                cmd += f'     [{cam},a]volume=1.0,asetpts=PTS-STARTPTS-{offsets[cam]:.3f}/TB[a{cam}_adj]; \\\n';
        cmd += '     '
        for cam, cam_list in enumerate(files):
            cmd += f'[a{cam}_adj]'
        cmd += f'amix=inputs={len(files)}:duration=longest:dropout_transition=2[aud_mix]; \\\n';

    """
    Tile the video in a 2x2 matrix.

    Stack the first two cameras left to right.
    Stack the second two cameras left to right.
    Stack the two stacks vertically.
    """
    cmd += '     [scaled0][scaled1]hstack[top]; \\\n'
    cmd += '     [scaled2][scaled3]hstack[bottom]; \\\n'
    cmd += '     [top][bottom]vstack[matrix]; \\\n'
    cmd += '     [matrix]fps=fps=30[outv];" \\\n'

    """
    Send the final video to the output.
    """
    cmd += '-map "[outv]" \\\n'
    
    """
    Send the audio to the output.
    """
    if one_audio:
        """
        A single stereo stream.
        """
        cmd += '-map "[aud_mix]" \\\n'
    else:
        """
        All 4 audio streams individually.
        """
        for cam, cam_list in files:
            if cam > 0:
                cmd += ' '
            first = False
            cmd += f'-map "[a{cam}_adj]"'
            cam += 1
        cmd += ' \\\n'


    """
    How to encode the final video and audio:
        - -c:v libx264, aka H.264/MPEG-4 AVC
        - -preset veryfast
           - Other options: ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow
           - Controls encoding speed, and resulting output file size.  Tweak down
             on faster / hardware accelerated computers.
        - -crf 21, aka Constant Rate Factor
           - 18-28 is generally acceptable.
           - Smaller values == larger files and more "quality"
        - -refs 4, aka Reference Frames
           - How many frames the encoder can look at, higher == smaller files but more CPU.
        - H.264 Profile "high"
           - Other options: baseline, main, high, high10, high442, high444
        - GOP size
           - I'm told 60 should work everywhere, and more may not work with some players.
        - B-frames between i/p-frames
           - I'm told 2 should work everywhere, and more may not work with some players.
        - Move the moov atom to the start of the file to allow immediate playback when streaming
        - -c:a aac, aka AAC-LC
        - -b:a, set audio bitrate to 192kbps

    TODO: Add more presets for different use cases.
    """
    if encode == 'YouTube':
        """
        I asked gemini.google.com for the best settings for uploading to YouTube.
        """
        cmd += '-c:v libx264 -preset veryfast -crf 21 -refs 4 -profile:v high -g 60 -bf 2 -movflags faststart \\\n'
        cmd += '-c:a aac -b:a 384k -ar 48000 -ac 2 \\\n'
    elif encode == 'H265':
        cmd += '-c:v libx265 -preset veryfast -crf 28 -profile:v main -g 60 -bf 4 -x265-params "fast-intra=1:no-open-gop=1:ref=4" \\\n'
        cmd += '-c:a aac -b:a 384k -ar 48000 -ac 2 \\\n'

    else:
        cmd += '-c:v libx264 -preset veryfast -crf 29 -qp 10 -profile:v main -vf format=yuv420p \\\n'
        cmd += '-c:a aac -b:a 192k \\\n'

    """
    Set the output file name.
    """
    cmd += f'{output}\n'

    return cmd


def compute_offsets(frames: list[int]) -> tuple[float, float, float, float]:
    if len(frames) != 6:
        print("Wrong number of frame arguments.")
        sys.exit(1)

    # Compute deltas between videos, camera1 is at offset 0.0 by convention, so:
    cam2 = frames[1] - frames[0]  # camera2 is this offset from camera1
    cam3 = frames[3] - frames[2]  # camera3 is this offset from camera2
    cam4 = frames[5] - frames[4]  # camera4 is this offset from camera3

    cam1cam2 = cam2
    cam1cam3 = cam2 + cam3
    cam1cam4 = cam2 + cam3 + cam4

    smallest = min(cam1cam2, cam1cam3, cam1cam4)
    base = 0.0
    # If one or more times was negative, shift them all so one is zero and the rest
    # are positive.
    if smallest < 0:
        base -= smallest
        cam1cam2 -= smallest
        cam1cam3 -= smallest
        cam1cam4 -= smallest

    return (base / 60.0, cam1cam2 / 60.0, cam1cam3 / 60.0, cam1cam4 / 60.0)

if __name__ == "__main__":
    my_name = os.path.basename(sys.argv[0])

    # Set up argument parser
    parser: argparse.ArgumentParser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="""\
Process multiple 1080P video files into a 4K 4x4 matrix.

Takes an input directory tree like this:

    /path/to/directory/camera1/
    /path/to/directory/camera2/
    /path/to/directory/camera3/
    /path/to/directory/camera4/

Each directory should contain one or more 1080P input movie files,
typically copied straight off the camera.

The user then needs to use other software to find frames that are
in sync between the videos, for example:

   camera1 frame 67 is in sync with camera2 frame 102
   camera2 frame 87 is in sync with camera3 frame 95
   camera3 frame 124 is in sync with camera4 frame 87

If the frames are omitted they are all treated as zero.
""",
        epilog=f"Example: {my_name} /path/to/directory 67 102 87 95 124 87",
    )
    parser.add_argument(
        "directory",
        type=str,
        help="The base directory to search for 'cameraX' subdirectories."
    )
    # Argument for the four frame integers
    parser.add_argument(
        "frame",
        type=int,
        nargs="*",
        default=[0, 0, 0, 0, 0, 0],
        help="Six integers representing cam1 cam2 cam2 cam3 cam3 cam4"
    )

    # Parse command-line arguments
    args: argparse.Namespace = parser.parse_args()
    input_directory: str = args.directory

    if len(input_directory) == 0:
        print("No input directory given.")
        sys.exit(1)

    if not os.path.exists(input_directory):
        print(f"Directory {input_directory} does not exist.")
        sys.exit(1)

    offsets = compute_offsets(args.frame)

    # Call the function to collect files
    # The return type is now list[list[str]]
    all_camera_mp4s: list[list[str]] = collect_mp4_files(input_directory)

    if all_camera_mp4s:
        command = construct_ffmpeg_args(all_camera_mp4s, offsets, True, input_directory + "/combined.mp4")
        print(command)
